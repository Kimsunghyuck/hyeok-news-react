"""
Supabase ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ëª¨ë“ˆ
ëª¨ë“  ë‚ ì§œ/ì‹œê°„ì€ í•œêµ­ í‘œì¤€ì‹œ(KST)ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
"""

import os
from supabase import create_client, Client
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any

# Supabase ì„¤ì •
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    raise ValueError("âŒ SUPABASE_URL ë° SUPABASE_SERVICE_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤!")

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

# í•œêµ­ ì‹œê°„ëŒ€ (KST = UTC+9)
KST = timezone(timedelta(hours=9))


def get_kst_now_str():
    """
    í˜„ì¬ í•œêµ­ ì‹œê°„ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    ISO 8601 í˜•ì‹, timezone ì •ë³´ í¬í•¨: 2025-12-29T09:00:00+09:00
    """
    return datetime.now(KST).isoformat()


def parse_scraped_at(scraped_at_str: str) -> str:
    """
    scraped_at ë¬¸ìì—´ì„ KSTë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        scraped_at_str: ISO 8601 í˜•ì‹ì˜ ë‚ ì§œ/ì‹œê°„ ë¬¸ìì—´

    Returns:
        KST timezoneì„ í¬í•¨í•œ ISO 8601 ë¬¸ìì—´
    """
    try:
        # ISO í˜•ì‹ íŒŒì‹±
        dt = datetime.fromisoformat(scraped_at_str.replace('Z', '+00:00'))

        # timezoneì´ ì—†ìœ¼ë©´ KSTë¡œ ê°„ì£¼
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=KST)
        else:
            # ë‹¤ë¥¸ timezoneì´ë©´ KSTë¡œ ë³€í™˜
            dt = dt.astimezone(KST)

        return dt.isoformat()
    except:
        # íŒŒì‹± ì‹¤íŒ¨ì‹œ í˜„ì¬ KST ì‹œê°„ ë°˜í™˜
        return get_kst_now_str()


def save_news_to_db(news_items: List[Dict[str, Any]]) -> Dict[str, int]:
    """
    ë‰´ìŠ¤ ë°ì´í„°ë¥¼ Supabaseì— ì €ì¥

    Args:
        news_items: ë‰´ìŠ¤ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸

    Returns:
        {"success": ì„±ê³µ ê°œìˆ˜, "failed": ì‹¤íŒ¨ ê°œìˆ˜, "duplicate": ì¤‘ë³µ ê°œìˆ˜}
    """
    if not news_items:
        print("âš ï¸ ì €ì¥í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {"success": 0, "failed": 0, "duplicate": 0}

    success_count = 0
    failed_count = 0
    duplicate_count = 0

    print(f"\nğŸ“¦ ì´ {len(news_items)}ê°œ ë‰´ìŠ¤ë¥¼ DBì— ì €ì¥ ì¤‘...")

    for idx, item in enumerate(news_items, 1):
        try:
            # scraped_atì„ KSTë¡œ ë³€í™˜
            scraped_at = item.get("scraped_at")
            if scraped_at:
                scraped_at_kst = parse_scraped_at(scraped_at)
            else:
                scraped_at_kst = get_kst_now_str()

            # ë°ì´í„° ì¤€ë¹„
            data = {
                "title": item["title"],
                "url": item["url"],
                "date": item["date"],
                "category": item.get("category", item.get("main_category", "")),
                "category_en": item.get("category_en"),
                "source": item["source"],
                "source_en": item.get("source_en"),
                "image_url": item.get("image_url"),
                "scraped_at": scraped_at_kst
            }

            # Upsert: URLì´ ê°™ìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…
            result = supabase.table("news").upsert(
                data,
                on_conflict="url"
            ).execute()

            # ì„±ê³µ
            if result.data:
                success_count += 1
                if idx % 10 == 0:  # 10ê°œë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
                    print(f"  ì§„í–‰: {idx}/{len(news_items)} ({success_count} ì„±ê³µ)")
            else:
                duplicate_count += 1

        except Exception as e:
            error_msg = str(e)

            # ì¤‘ë³µ í‚¤ ì—ëŸ¬ (ì´ë¯¸ ì¡´ì¬í•˜ëŠ” URL)
            if "duplicate key" in error_msg.lower() or "unique constraint" in error_msg.lower():
                duplicate_count += 1
            else:
                failed_count += 1
                print(f"  âŒ [{idx}] ì €ì¥ ì‹¤íŒ¨: {item['title'][:30]}...")
                print(f"     ì—ëŸ¬: {error_msg[:100]}")

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… ì €ì¥ ì™„ë£Œ!")
    print(f"   ì„±ê³µ: {success_count}ê°œ")
    print(f"   ì¤‘ë³µ: {duplicate_count}ê°œ")
    print(f"   ì‹¤íŒ¨: {failed_count}ê°œ")

    return {
        "success": success_count,
        "failed": failed_count,
        "duplicate": duplicate_count
    }


def get_news_count_by_date(date: str) -> int:
    """
    íŠ¹ì • ë‚ ì§œì˜ ë‰´ìŠ¤ ê°œìˆ˜ ì¡°íšŒ

    Args:
        date: YYYY-MM-DD í˜•ì‹

    Returns:
        ë‰´ìŠ¤ ê°œìˆ˜
    """
    try:
        result = supabase.table("news") \
            .select("id", count="exact") \
            .eq("date", date) \
            .execute()

        return result.count if hasattr(result, 'count') else 0
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return 0


def get_total_news_count() -> int:
    """
    ì „ì²´ ë‰´ìŠ¤ ê°œìˆ˜ ì¡°íšŒ

    Returns:
        ì „ì²´ ë‰´ìŠ¤ ê°œìˆ˜
    """
    try:
        result = supabase.table("news") \
            .select("id", count="exact") \
            .execute()

        return result.count if hasattr(result, 'count') else 0
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return 0


def delete_old_news(days: int = 30) -> int:
    """
    ì˜¤ë˜ëœ ë‰´ìŠ¤ ì‚­ì œ (ê¸°ë³¸ 30ì¼)

    Args:
        days: ì‚­ì œí•  ê¸°ì¤€ ì¼ìˆ˜

    Returns:
        ì‚­ì œëœ ë‰´ìŠ¤ ê°œìˆ˜
    """
    # KST ê¸°ì¤€ìœ¼ë¡œ cutoff ë‚ ì§œ ê³„ì‚°
    cutoff_date = (datetime.now(KST) - timedelta(days=days)).date()

    try:
        result = supabase.table("news") \
            .delete() \
            .lt("date", str(cutoff_date)) \
            .execute()

        deleted_count = len(result.data) if result.data else 0
        print(f"ğŸ—‘ï¸ {cutoff_date} ì´ì „ ë‰´ìŠ¤ {deleted_count}ê°œ ì‚­ì œ ì™„ë£Œ")

        return deleted_count
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
        return 0


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª Supabase ì—°ê²° í…ŒìŠ¤íŠ¸...")
    print(f"í˜„ì¬ KST ì‹œê°„: {get_kst_now_str()}")

    # í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ ì €ì¥
    test_news = [{
        "title": "í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ (KST)",
        "url": f"https://test.com/{datetime.now().timestamp()}",
        "date": datetime.now(KST).date().isoformat(),
        "category": "ì •ì¹˜",
        "source": "í…ŒìŠ¤íŠ¸",
        "image_url": "https://via.placeholder.com/300x200",
        "scraped_at": get_kst_now_str()
    }]

    save_news_to_db(test_news)
    print("\nâœ… Supabase ì—°ê²° ì„±ê³µ!")
